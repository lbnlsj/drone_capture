#!/usr/bin/env python3

import numpy as np
import time
from multi_drone_env import MultiDroneEnvironment
from algorithms.ham_dtan_maddpg import HAMDTANMADDPGAlgorithm


def test_short_training():
    """æµ‹è¯•çŸ­æ—¶é—´è®­ç»ƒ"""
    print("=" * 60)
    print("HAM-DTAN-MADDPG çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºç¯å¢ƒ
    env = MultiDroneEnvironment(num_friendly_drones=9, num_enemy_drones=3)
    
    print(f"ç¯å¢ƒä¿¡æ¯:")
    print(f"- è§‚æµ‹ç©ºé—´: {env.observation_space.shape}")
    print(f"- åŠ¨ä½œç©ºé—´: {env.action_space.shape}")
    print(f"- æˆ‘æ–¹æ— äººæœº: {env.num_friendly_drones}")
    print(f"- æ•Œæ–¹æ— äººæœº: {env.num_enemy_drones}")
    
    # åˆ›å»ºç®—æ³•
    algorithm = HAMDTANMADDPGAlgorithm(
        num_agents=9,
        obs_dim=78,
        action_dim=3,
        num_enemies=3
    )
    
    print(f"ç®—æ³•å‚æ•°é‡: {algorithm.get_algorithm_info()['total_parameters']:,}")
    
    # çŸ­æ—¶é—´è®­ç»ƒ
    num_episodes = 50
    print(f"\nå¼€å§‹è®­ç»ƒ {num_episodes} ä¸ªepisodes...")
    
    start_time = time.time()
    total_rewards = []
    
    for episode in range(num_episodes):
        obs, info = env.reset()
        algorithm.reset_noise()
        algorithm.reset_memory()
        
        total_reward = 0
        episode_length = 0
        
        done = False
        while not done and episode_length < 100:  # é™åˆ¶episodeé•¿åº¦
            # é€‰æ‹©åŠ¨ä½œ
            actions = algorithm.select_actions(obs, add_noise=True)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_obs, reward, terminated, truncated, next_info = env.step(actions)
            
            # å­˜å‚¨ç»éªŒ
            algorithm.store_transition(obs, actions.flatten(), reward, next_obs, terminated or truncated)
            
            total_reward += reward
            episode_length += 1
            done = terminated or truncated
            obs = next_obs
            info = next_info
        
        total_rewards.append(total_reward)
        
        # æ›´æ–°ç½‘ç»œ
        if episode % 2 == 0 and len(algorithm.replay_buffer) > 100:
            losses = algorithm.update(batch_size=64)
        
        # æ‰“å°è¿›åº¦
        if episode % 10 == 0:
            recent_avg = np.mean(total_rewards[-10:]) if len(total_rewards) >= 10 else np.mean(total_rewards)
            print(f"Episode {episode}: å¹³å‡å¥–åŠ± {recent_avg:.2f}, Episodeé•¿åº¦ {episode_length}")
    
    training_time = time.time() - start_time
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
    print(f"ğŸ“Š å¹³å‡å¥–åŠ±: {np.mean(total_rewards):.2f}")
    print(f"ğŸ“ˆ æœ€å10ä¸ªepisodeså¹³å‡å¥–åŠ±: {np.mean(total_rewards[-10:]):.2f}")
    print(f"ğŸ”¢ ç»éªŒæ± å¤§å°: {len(algorithm.replay_buffer)}")
    
    # æµ‹è¯•è®­ç»ƒåçš„è¡¨ç°
    print("\nğŸ¯ æµ‹è¯•è®­ç»ƒåè¡¨ç°...")
    test_rewards = []
    test_success = []
    
    for test_ep in range(10):
        obs, info = env.reset()
        algorithm.reset_memory()
        
        total_reward = 0
        episode_length = 0
        
        done = False
        while not done and episode_length < 200:
            actions = algorithm.select_actions(obs, add_noise=False)  # ç¡®å®šæ€§åŠ¨ä½œ
            next_obs, reward, terminated, truncated, next_info = env.step(actions)
            
            total_reward += reward
            episode_length += 1
            done = terminated or truncated
            obs = next_obs
            info = next_info
        
        test_rewards.append(total_reward)
        test_success.append(terminated)
        
        if test_ep < 3:  # æ‰“å°å‰3ä¸ªæµ‹è¯•episodeçš„è¯¦ç»†ä¿¡æ¯
            final_coverage = sum(status['satisfied'] for status in info['coverage_status'])
            final_intercept = sum(status['intercepted'] for status in info['intercept_status'])
            print(f"  æµ‹è¯• {test_ep+1}: å¥–åŠ± {total_reward:.2f}, è¦†ç›– {final_coverage}/3, æ‹¦æˆª {final_intercept}/3")
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  - å¹³å‡å¥–åŠ±: {np.mean(test_rewards):.2f}")
    print(f"  - æˆåŠŸç‡: {np.mean(test_success):.2%}")
    
    env.close()
    
    return {
        'training_time': training_time,
        'avg_training_reward': np.mean(total_rewards),
        'avg_test_reward': np.mean(test_rewards),
        'test_success_rate': np.mean(test_success)
    }


if __name__ == "__main__":
    try:
        results = test_short_training()
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! ç»“æœ: {results}")
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()